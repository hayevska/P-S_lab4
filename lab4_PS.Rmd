---
title: "P&S-2025: Lab assignment 4"
author: "Yustyna Hayevska, Oleksii Lasiichuk, Ivan Zarytskyi"
output:
  html_document:
    df_print: paged
---

### Work breakdown:

-   Yustyna Hayevska (Task 3)

-   Oleksii Lasiichuk (Task 1, 2)

-   Ivan Zarytskyi (Task 4)

### Data generation
```{r}
# team ID
n <- 13
set.seed(n)

# function gets fractional part of a number (5.7 -> 0.7)
get_fractional <- function(x) {
  return(x - floor(x))
}

# 100 values of x, and 50 of y (150 total)
k_values <- 1:150

# apply formula from the assignment
raw_values <- k_values * log(k_values^2 * n + pi)

a_values <- get_fractional(raw_values)

X <- qnorm(a_values[1:100])
Y <- qnorm(a_values[101:150])
```


### Task 1
Hypothesis:
$$H_0: \mu_1 = \mu_2$$
$$H_1: \mu_1 \neq \mu_2$$

$\sigma_1^2 = \sigma_2^2 = 1$ (Variances are known).

We are testing the equality of means between two independent populations. Since the population variances are known ($\sigma^2 = 1$), the two sample Z-test is the appropriate standard test. (If variances were unknown, we would use a T-test).

For a significance level $\alpha = 0.05$, we reject $H_0$ if $|Z_{stat}| > Z_{0.025}$.

$Z_{0.025} \approx 1.96$.
So rejection region is: $(-\infty, -1.96) \cup (1.96, \infty)$.

```{r}
sigma1_sq <- 1
sigma2_sq <- 1
n_x <- 100
n_y <- 50
alpha <- 0.05

mean_x <- mean(X)
mean_y <- mean(Y)

# Z-test statistic calculation
# formula: z = (mean_x - mean_y) / sqrt(sigma1^2/n_x + sigma2^2/n_y)
standard_error <- sqrt((sigma1_sq / n_x) + (sigma2_sq / n_y))
z_stat <- (mean_x - mean_y) / standard_error

# P-value for two-sided test: p = 2 * P(Z > |z_stat|)
p_value_z <- 2 * (1 - pnorm(abs(z_stat)))


cat("Sample mean X:", mean_x, "\n")
cat("Sample mean Y:", mean_y, "\n")
cat("Z-Statistic:", z_stat, "\n")
cat("P-value:", p_value_z, "\n")

```

Since the p-value ($0.663$) is significantly higher than our chosen significance level ($\alpha = 0.05$), we fail to reject the null hypothesis.

This indicates that the difference between the sample means ($0.0198$ vs $-0.0557$) is statistically insignificant. There is no evidence that populations for $X$ and $Y$ have different means. 

### Task 2
Hypothesis:
$$H_0: \sigma_1^2 = \sigma_2^2$$
$$H_1: \sigma_1^2 > \sigma_2^2$$
$\mu_1$ and $\mu_2$ (means are unknown)

We are going to use F-test for equality of variances. When testing the equality of variances from two normal populations with unknown means, the ratio of sample variances follows an F-distribution.

Rejection Region:This is a one-sided test (greater than). We reject $H_0$ if $F_{stat} > F_{\alpha, n_x-1, n_y-1}$.For $\alpha=0.05$, $df_1 = 99$, $df_2 = 49$.

```{r}
var_x <- var(X)
var_y <- var(Y)

#F-Test formula: F = S_x^2 / S_y^2
f_stat <- var_x / var_y

# P-value

# One-sided test (H1: sigma1^2 > sigma2^2): P(F > f_stat)
# In R, pf() gives P(F < q), so we use 1 - pf()
p_value_f <- 1 - pf(f_stat, n_x - 1, n_y - 1)

# Critical value for rejection region
f_critical <- qf(1 - alpha, n_x - 1, n_y - 1)

cat("Sample Variance X:", var_x, "\n")
cat("Sample Variance Y:", var_y, "\n")
cat("F-Statistic:", f_stat, "\n")
cat("Critical Value:", f_critical, "\n")
cat("P-value:", p_value_f, "\n")

```

We conducted a one-sided F-test to check if the variance of population X is greater than population Y ($H_0: \sigma_1^2 = \sigma_2^2$ vs $H_1: \sigma_1^2 > \sigma_2^2$).

The calculated F-statistic is 1.367, which is less than the critical value of 1.531. Correspondingly, the p-value is 0.113

Since the p-value ($0.113$) is higher than our chosen significance level ($\alpha = 0.05$), we fail to reject the null hypothesis.This indicates that while the sample variance of X ($1.10$) appears larger than Y ($0.80$), this difference is statistically insignificant. The data does not provide sufficient evidence to claim that the true population variance of X is greater than that of Y.

## Task 3

Applies the Kolmogorov-Smirnov test to investigate the distributional properties of sets generated via the inverse normal CDF.

Data were generated using: $a_k = \{k \ln(k^2 n + \pi)\}, \quad k \geq 1$

where ${x} = x - \lfloor x \rfloor$ denotes the fractional part and $n$ is the student ID. Samples were obtained as:

$x_k = \Phi^{-1}(a_k), \quad k = 1, \ldots, 100$

$y_l = \Phi^{-1}(a_{l+100}), \quad l = 1, \ldots, 50$

Three hypotheses were tested using the KS test at significance level $\alpha = 0.05$:

(a) $\{x_k\}_{k=1}^{100}$ are normally distributed (with parameters calculated from the sample);

(b) $\{|x_k|\}_{k=1}^{100}$ are exponentially distributed with $\lambda = 1$;

(c) $\{x_k\}_{k=1}^{100}$ and $\{y_l\}_{l=1}^{50}$ have the same distributions.

```{r}
set.seed(id)

n <- id
k <- 1:100
a_func <- function(i){
  a <- i * log(i^2 * n + pi)
  a_frac <- a- floor(a)
  return (a_frac)
}

k <- 1:100
l <- 101:150

x <- qnorm(sapply(k, a_func))
y <- qnorm(sapply(l, a_func))

mu_x <- mean(x)
sd_x <- sd(x)

#a)
ks.test_a <- ks.test(x, "pnorm", mean = mu_x, sd = sd_x)
cat("a) Test if x is normally distributed\n")
ks.test_a

#b)
ks.test_b <- ks.test(x, "pexp", rate = 1)
cat("b) Test if x is exponentially distributed\n")
ks.test_b

#c)
ks.test_c <- ks.test(x, y)
cat("c) Test if x and y have the same distribution\n")
ks.test_c
```

Explain the main idea behind the Kolmogorov-Smirnov test and comment on the outcomes of the test.

**The Kolmogorov-Smirnov test** measures the **maximum vertical distance** between two cumulative distribution functions (CDFs):\
- One-sample KS test: Compares the empirical CDF of a sample to a it's theoretical CDF\
- Two-sample KS test: Compares the empirical CDFs of two samples

For a sample of size n, **the empirical CDF** is:\
$F_n(x) = \frac{\#\{i | x_i \leq x\}}{n}$

The **KS test statistic** is defined as:\
$D = \max_x |F_n(x) - F_0(x)|$\
Where:\
- $F_n(x)$ is the empirical cumulative distribution function of the sample\
- $F_0(x)$ is the theoretical CDF under the null hypothesis

**Results**:\
- Large D (\> 0.50): ECDF deviates substantially from the CDF - reject $H_0$\
- Small D (\< 0.25): ECDF closely matches the CDF - do not reject $H_0$ If 0.25 \<= D \<= 0.56, our distributions have poor fit, which indicates that we are likely to reject the null hypothesis, but not sure enough, so we rely on p-value more than usual.

**Advantages**:\
- Doesn't require normality\
- Sensitive to location, scale and differences, so is very precise\
- Applies to any continuous distribution\
- Measures the maximum discrepancy directly\

### a) Test if x is normally distributed

data: x\
D = 0.066605, p-value = 0.7667

The maximum vertical distance between the empirical CDF of x and the theoretical normal CDF is only 0.0666 (6.66%).\
This is an **extremely small discrepancy**.

The high p-value (0.7667) indicates that such a small discrepancy would occur approximately 77% of the time, if x truly followed a normal distribution.\
**We fail to reject** $H_0$.

**Conclusion**:\
$\{x_k\}_{k=1}^{100}$ is highly consistent with a normal distribution. The empirical and theoretical CDFs overlap almost perfectly.

### b) Test if x is exponentially distributed

data: x\
D = 0.53, p-value \< 2.2e-16

The maximum vertical distance between the empirical CDF of x and the theoretical exponential CDF is 0.53 (53%).\
This is a **high discrepancy**.

The reasons for it:\
- Exp. is right-skewed; Normal is symmetric;\
- X contains negative values, while values from Exp. dist. are always \>= 0;\
- Location differs: mean(x) = -0.045 and mean of exp(1) = 1;

P-value \< 2.2e-16, which indicates that such a large discrepancy would never occur by random chance, if x truly followed an exponential distribution.\
**We reject the null hypothesis**.

**Conclusion**:\
$\{x_k\}_{k=1}^{100}$ are not exponentially distributed with $\lambda = 1$;

### c) Test if x and y have the same distribution 

data: x and y\
D = 0.14, p-value = 0.5185

The maximum vertical distance between the empirical CDFs of x and y is 0.14 (14%).\
This is a **modest discrepancy**.

The reasons for it:\
- Similar location (means = 0), spread (var = 1), ranges (-3;3);\
- Same generation from $N(0, 1)$;\
- Differs by sample size (50 and 100).

P-value = 0.5185, which indicates that difference of 14% or bigger would occur approximately 52% of the time, if x and y truly came from the same distribution.\
**We fail to reject** $H_0$.

**Conclusion**:\
$\{x_k\}_{k=1}^{100}$ and $\{y_l\}_{l=1}^{50}$ have pretty similar distributions.

## Summary
The Kolmogorov-Smirnov (KS) test was applied to assess the distributional properties of samples generated via the inverse normal CDF. The data were constructed using the fractional part of a sequence passed through the normal quantile function. The KS test evaluates the maximum vertical discrepancy between empirical cumulative distribution functions (ECDFs) or between an ECDF and a theoretical CDF.

For hypothesis (a), the sample ${x_k}$ was tested against a normal distribution with estimated parameters; the test returned a p-value of 0.7667, indicating no significant deviation from normality. \
In (b), test against an exponential distribution with rate 1 gave a p-value < 2.2e-16, rejecting the hypothesis due to big differences in shape and properties. \
For (c), the two-sample KS test between ${x_k}$ and ${y_l}$ produced a p-value of 0.5185, indicating no significant difference in their distributions, aligning with both being derived from the same underlying normal distribution. \

Overall, the results show that the generated samples behave like normally distributed, are clearly not exponential, and have very similar distributions across different subsets of the data.

### Task 4

...